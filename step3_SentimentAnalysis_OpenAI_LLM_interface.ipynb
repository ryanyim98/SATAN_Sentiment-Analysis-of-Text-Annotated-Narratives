{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps5Pb4dCyWKd"
      },
      "source": [
        "##Purpose of this Colab##\n",
        "\n",
        "Large language models are here to stay and many people have done interesting experiments exploring them and how they seem to capture aspects of human cognition.  In Psych 209-W23 the readings and lecture on Wed Feb 15 will cover some examples of this.  The purpose of this Colab is to give you tools to explore these models.  We provide it because we see several ways these tools could be extended to perform interesting experiments, including possible class projects!\n",
        "\n",
        "One tool allows you to present a prompt to one of the variants of GPT3, and then to assess its prediction for the next word following the prompt.  Inspired be a recent talk by Richard Futrell at UC Irvine (formerly a Stanford undergrad and master's student!) and based on some code he provided, we allow you to present a prompt, and get back the language model's top 5 choices for the next word, as well as the log of the probability it estimates for each choice.\n",
        "\n",
        "We use examples from Richard's talk for this: Given 'The children went outside to' as the prompt.  Here the probability of 'play' is very high, but with a second prompt 'The children went inside to' the probability of 'play' goes way down, and the probabilities of some other alternatives go up.  There are a huge number of questions you can explore, including some of the ones covered in the Dasgupta, Lampinen *et al* paper listed as a reading for Feb 13, starting from this tool and adapting it in various ways!\n",
        "\n",
        "The second tool allows you to present a prompt and see how the model continues from there.  In the second case, the model *samples* words according to it's estimates of their probabilities.  For example with the first prompt above, 'play' is likely to be chosen by this process.  The model then feeds its choice in as the first word of the completion, and then repeats the process.  You can tell it the maximum number of words to sample and also you can tell it to stop if it ever hits one of a set of specified stop sequences, such as '.' or '!', which are common end-of-sentence markers.  So following the first prompt mentioned before, 'play' would likely be the next word, but the output may vary over the 10 runs from there.  \n",
        "\n",
        "NOTE: We are using the Openai *Completions* endpoint.  There are parameters that you can control that affect the sampling process, and you can read more about them in the [Documentation](https://platform.openai.com/docs/api-reference/completions/create) from the Open AI web site.\n",
        "\n",
        "To get started, Make your own copy of this Colab, and proceed from there!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xESgSmSrCrT"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJ2vErpLk8f"
      },
      "source": [
        "##Make your own copy of this Colab\n",
        "\n",
        "Before doing anything else, including running this Colab, please make your own copy of it (*File->Save a Copy in Drive*)\n",
        "\n",
        "###Uncomment a Crucial Line Below\n",
        "\n",
        "To prevent accidental running of this Colab, a crucial line in the next codeblock defining the OPENAI_API_KEY has been commented out.  The Colab will not run until you uncomment that line.  After you have uncommented that line, connect the Colab to a server and then run the next code block.\n",
        "\n",
        "You may see some error messages about dependencies, but they should not prevent you from using the colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pncWUeLgmoZu",
        "outputId": "1713d068-f534-4a4a-89af-05dabdbba755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from openai==0.28) (3.11.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.13.2)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from pandas) (2.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/yanyan/miniforge3/envs/newenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pandas\n",
            "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install pandas\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "# Read the API key from a JSON file\n",
        "with open('openai_api_key.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "openai_api_key = data['api_key']\n",
        "OPENAI_API_KEY = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7m_ABREYY-0"
      },
      "source": [
        "## Part 1. Analysis of word at the end of the sequence (Unidirectional model only)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0EgW0u6pbHM"
      },
      "source": [
        "### Basic methods for this section.\n",
        "Method `get_completions_with_logprobs` prints out the 5 tokens with the highest probability to be the word immediately following the prompt. For each token, the code prints its log probability and its probability.  After that, it prints the sum of the probabilities of the top 5 tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "Xsx14quqmu57",
        "outputId": "5ec111a6-bdfb-4d63-818b-03e2cd994fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "analysing:  :)\n",
            "Attempt 1 - Response 1: +1\n",
            "Attempt 1 - Response 2: +1\n",
            "Attempt 1 - Response 3: 0.9\n",
            "Attempt 1 - Response 4: +1\n",
            "Attempt 1 - Response 5: +1\n",
            "[1.0, 1.0, 0.9, 1.0, 1.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "def get_emotionality_rating(sentence, max_attempts=5,brief_input=True):\n",
        "    prompt = f\"Rate the following sentence on its emotionality from very negative (-1) to very positive (+1):\\n\\n\\\"{sentence}\\\"\\n\\nAnswer with a number:\"\n",
        "    if brief_input == False:\n",
        "        print(\"analysing: \",sentence)\n",
        "    openai.api_key = OPENAI_API_KEY  # Make sure this is defined\n",
        "\n",
        "    ratings = []\n",
        "    attempts = 0\n",
        "\n",
        "    while len(ratings) < 5 and attempts < max_attempts:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=5,\n",
        "            temperature=0.7,\n",
        "            n=5  # Ask for 5 completions\n",
        "        )\n",
        "\n",
        "        for i, choice in enumerate(response.choices):\n",
        "            content = choice.message.content.strip()\n",
        "            if not brief_input:\n",
        "                print(f\"Attempt {attempts+1} - Response {i+1}:\", content)\n",
        "            try:\n",
        "                rating = float(content)\n",
        "                ratings.append(rating)\n",
        "            except ValueError:\n",
        "                if not brief_input:\n",
        "                    print(f\"Non-numeric response: '{content}', skipping.\")\n",
        "\n",
        "            if len(ratings) >= 5:\n",
        "                break\n",
        "\n",
        "        attempts += 1\n",
        "\n",
        "    if len(ratings) < 5 & brief_input == False:\n",
        "        print(\"Warning: Could not collect 5 valid numeric ratings after maximum attempts.\")\n",
        "\n",
        "    return ratings[:5]  # Return exactly 5 ratings\n",
        "\n",
        "\n",
        "# Example usage\n",
        "print(get_emotionality_rating(\":)\",5,False))\n",
        "print(get_emotionality_rating(\"Aur Naur\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row 0: Mean GPT rating = -0.76\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Length of values (1) does not match length of index (307)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Mean GPT rating = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_rating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add the new column\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtempdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m mean_ratings\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save back to the same file\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tempdf\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./sentiment_analysis.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.10/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
            "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.10/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/newenv/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (307)"
          ]
        }
      ],
      "source": [
        "tempdf = pd.read_csv(os.path.join('./sentiment_analysis.csv'))\n",
        "\n",
        "# Prepare a list to collect mean ratings\n",
        "mean_ratings = []\n",
        "\n",
        "for idx, row in tempdf.iterrows():\n",
        "    text = row.get('sentence', '')\n",
        "    if pd.isna(text) or not text.strip():\n",
        "        mean_rating = np.nan\n",
        "    else:\n",
        "        ratings = get_emotionality_rating(text)\n",
        "        mean_rating = np.nanmean(ratings)  # mean ignoring NaN if any\n",
        "        mean_ratings.append(mean_rating)\n",
        "        print(f\"Row {idx}: Mean GPT rating = {mean_rating}\")\n",
        "\n",
        "# Add the new column\n",
        "tempdf['gpt_rating'] = mean_ratings\n",
        "\n",
        "# Save back to the same file\n",
        "# tempdf.to_csv('./sentiment_analysis.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float64(-0.76)]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>sentence</th>\n",
              "      <th>syuzhet_sentiment_score</th>\n",
              "      <th>word_scores</th>\n",
              "      <th>compound</th>\n",
              "      <th>pos</th>\n",
              "      <th>neu</th>\n",
              "      <th>neg</th>\n",
              "      <th>but_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user_106_testimonial_105_stimuli_363_.tsv</td>\n",
              "      <td>5.36</td>\n",
              "      <td>17.52</td>\n",
              "      <td>So I grew up in Del Paso Heights, which is, it...</td>\n",
              "      <td>-2.65</td>\n",
              "      <td>{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>-0.542</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.863</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_106_testimonial_105_stimuli_363_.tsv</td>\n",
              "      <td>18.60</td>\n",
              "      <td>30.20</td>\n",
              "      <td>Well, one of the good things is I had a neighb...</td>\n",
              "      <td>3.20</td>\n",
              "      <td>{1.1, 0, 0, 0, 1.9, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>0.886</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user_106_testimonial_105_stimuli_363_.tsv</td>\n",
              "      <td>30.38</td>\n",
              "      <td>37.36</td>\n",
              "      <td>We went camping, doing nature stuff and just g...</td>\n",
              "      <td>1.20</td>\n",
              "      <td>{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.3...</td>\n",
              "      <td>0.511</td>\n",
              "      <td>0.163</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user_106_testimonial_105_stimuli_363_.tsv</td>\n",
              "      <td>37.36</td>\n",
              "      <td>40.48</td>\n",
              "      <td>It was a great experience for me.</td>\n",
              "      <td>0.50</td>\n",
              "      <td>{0, 0, 0, 3.1, 0, 0, 0}</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.406</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user_106_testimonial_105_stimuli_363_.tsv</td>\n",
              "      <td>42.70</td>\n",
              "      <td>54.72</td>\n",
              "      <td>However, one night we went to Scouts and I rem...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>0.572</td>\n",
              "      <td>0.121</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>user_84_testimonial_83_stimuli_285_.tsv</td>\n",
              "      <td>106.46</td>\n",
              "      <td>118.40</td>\n",
              "      <td>And I think they resented that for a long time...</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>{0, 0, 0, 0, -1.6, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>-0.382</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>user_84_testimonial_83_stimuli_285_.tsv</td>\n",
              "      <td>118.40</td>\n",
              "      <td>119.96</td>\n",
              "      <td>He was the all star.</td>\n",
              "      <td>0.60</td>\n",
              "      <td>{0, 0, 0, 0, 0}</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>user_84_testimonial_83_stimuli_285_.tsv</td>\n",
              "      <td>120.12</td>\n",
              "      <td>123.26</td>\n",
              "      <td>He was the special one.</td>\n",
              "      <td>0.80</td>\n",
              "      <td>{0, 0, 0, 1.7, 0}</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>user_84_testimonial_83_stimuli_285_.tsv</td>\n",
              "      <td>123.26</td>\n",
              "      <td>134.66</td>\n",
              "      <td>And I was the one who got the chores and did a...</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1.9, ...</td>\n",
              "      <td>-0.440</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>user_84_testimonial_83_stimuli_285_.tsv</td>\n",
              "      <td>137.14</td>\n",
              "      <td>149.72</td>\n",
              "      <td>So, you know, that was just cascaded from that...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>{0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     file_name  start_time  end_time  \\\n",
              "0    user_106_testimonial_105_stimuli_363_.tsv        5.36     17.52   \n",
              "1    user_106_testimonial_105_stimuli_363_.tsv       18.60     30.20   \n",
              "2    user_106_testimonial_105_stimuli_363_.tsv       30.38     37.36   \n",
              "3    user_106_testimonial_105_stimuli_363_.tsv       37.36     40.48   \n",
              "4    user_106_testimonial_105_stimuli_363_.tsv       42.70     54.72   \n",
              "..                                         ...         ...       ...   \n",
              "302    user_84_testimonial_83_stimuli_285_.tsv      106.46    118.40   \n",
              "303    user_84_testimonial_83_stimuli_285_.tsv      118.40    119.96   \n",
              "304    user_84_testimonial_83_stimuli_285_.tsv      120.12    123.26   \n",
              "305    user_84_testimonial_83_stimuli_285_.tsv      123.26    134.66   \n",
              "306    user_84_testimonial_83_stimuli_285_.tsv      137.14    149.72   \n",
              "\n",
              "                                              sentence  \\\n",
              "0    So I grew up in Del Paso Heights, which is, it...   \n",
              "1    Well, one of the good things is I had a neighb...   \n",
              "2    We went camping, doing nature stuff and just g...   \n",
              "3                    It was a great experience for me.   \n",
              "4    However, one night we went to Scouts and I rem...   \n",
              "..                                                 ...   \n",
              "302  And I think they resented that for a long time...   \n",
              "303                               He was the all star.   \n",
              "304                            He was the special one.   \n",
              "305  And I was the one who got the chores and did a...   \n",
              "306  So, you know, that was just cascaded from that...   \n",
              "\n",
              "     syuzhet_sentiment_score  \\\n",
              "0                      -2.65   \n",
              "1                       3.20   \n",
              "2                       1.20   \n",
              "3                       0.50   \n",
              "4                       0.50   \n",
              "..                       ...   \n",
              "302                    -1.00   \n",
              "303                     0.60   \n",
              "304                     0.80   \n",
              "305                    -0.75   \n",
              "306                     0.80   \n",
              "\n",
              "                                           word_scores  compound    pos  \\\n",
              "0    {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    -0.542  0.000   \n",
              "1    {1.1, 0, 0, 0, 1.9, 0, 0, 0, 0, 0, 0, 0, 0, 0,...     0.886  0.246   \n",
              "2    {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.3...     0.511  0.163   \n",
              "3                              {0, 0, 0, 3.1, 0, 0, 0}     0.625  0.406   \n",
              "4    {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     0.572  0.121   \n",
              "..                                                 ...       ...    ...   \n",
              "302  {0, 0, 0, 0, -1.6, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    -0.382  0.000   \n",
              "303                                    {0, 0, 0, 0, 0}     0.000  0.000   \n",
              "304                                  {0, 0, 0, 1.7, 0}     0.402  0.403   \n",
              "305  {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1.9, ...    -0.440  0.000   \n",
              "306  {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...     0.000  0.000   \n",
              "\n",
              "       neu    neg  but_count  \n",
              "0    0.863  0.137          0  \n",
              "1    0.754  0.000          0  \n",
              "2    0.837  0.000          0  \n",
              "3    0.594  0.000          0  \n",
              "4    0.879  0.000          0  \n",
              "..     ...    ...        ...  \n",
              "302  0.890  0.110          0  \n",
              "303  1.000  0.000          0  \n",
              "304  0.597  0.000          0  \n",
              "305  0.873  0.127          0  \n",
              "306  1.000  0.000          0  \n",
              "\n",
              "[307 rows x 11 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tempdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "newenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
